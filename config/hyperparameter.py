PPO_N_STEPS = 64
PPO_BATCH_SIZE = 32
PPO_N_EPOCHS = 5
TOTAL_TIMESTEPS = 1000

PPO_POLICY = "MultiInputPolicy"
MODEL_PATH_PPO = "weights/ppo.zip"
MODEL_PATH_LIDAR_ENCODER = "weights/global_feature_extractor.pth"